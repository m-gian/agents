{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m-gian/agents/blob/main/Create_Agent_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q google-genai"
      ],
      "metadata": {
        "id": "9Btp1x9hhQGw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcae239d-5a56-4fc0-e69e-ce5dc56f2a78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.3/53.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m713.3/713.3 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.9/234.9 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires google-auth==2.43.0, but you have google-auth 2.47.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from typing import Dict, List, Callable, Any, Literal, Optional, Union\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "from pydantic import BaseModel, Field"
      ],
      "metadata": {
        "id": "IOYmGSyqx0_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GEMINI_API_KEY = userdata.get('gemini_sosuke')\n",
        "client = genai.Client(api_key=GEMINI_API_KEY)"
      ],
      "metadata": {
        "id": "uHUqGrPuhmwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Tool:\n",
        "    def __init__(\n",
        "        self,\n",
        "        name: str,\n",
        "        description: str,\n",
        "        input_schema: Dict[str, Any],\n",
        "        output_schema: Dict[str, Any],\n",
        "        func: Callable[..., Any],\n",
        "    ):\n",
        "        self.name = name\n",
        "        self.description = description\n",
        "        self.input_schema = input_schema\n",
        "        self.output_schema = output_schema\n",
        "        self.func = func\n",
        "\n",
        "    def __call__(self, **kwargs):\n",
        "        return self.func(**kwargs)"
      ],
      "metadata": {
        "id": "d2rmAnxaQyZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ToolRegistry:\n",
        "    def __init__(self):\n",
        "        self.tools: Dict[str, Tool] = {}\n",
        "\n",
        "    def register(self, tool: Tool):\n",
        "        self.tools[tool.name] = tool\n",
        "\n",
        "    def get(self, name: str) -> Tool:\n",
        "        if name not in self.tools.keys():\n",
        "            raise ValueError(f\"Tool '{name}' not found\")\n",
        "        return self.tools[name]\n",
        "\n",
        "    def list_tools(self) -> List[Dict[str, Any]]:\n",
        "        return [\n",
        "            {\n",
        "                \"name\": tool.name,\n",
        "                \"description\": tool.description,\n",
        "                \"input_schema\": tool.input_schema.model_json_schema(),\n",
        "            }\n",
        "            for tool in self.tools.values()\n",
        "        ]\n",
        "    def get_tool_call_args_type(self) -> Union[BaseModel]:\n",
        "        input_args_models = [tool.input_schema for tool in self.tools.values()]\n",
        "        tool_call_args = Union[tuple(input_args_models)]\n",
        "        return tool_call_args\n",
        "    def get_tool_names(self) -> Literal[None]:\n",
        "        return Literal[*self.tools.keys()]\n"
      ],
      "metadata": {
        "id": "3glc8fGVfju5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add(a: int, b: int) -> int:\n",
        "    return a + b\n",
        "\n",
        "def multiply(a: int, b: int) -> int:\n",
        "    return a * b"
      ],
      "metadata": {
        "id": "8jOT8dPbx05k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "registry = ToolRegistry()\n",
        "\n",
        "class ToolAddArgs(BaseModel):\n",
        "    a: int\n",
        "    b: int\n",
        "\n",
        "class ToolMultiplyArgs(BaseModel):\n",
        "    a: int\n",
        "    b: int\n",
        "\n",
        "registry.register(\n",
        "    Tool(\n",
        "        name=\"add\",\n",
        "        description=\"Add two numbers\",\n",
        "        input_schema=ToolAddArgs,\n",
        "        output_schema={\"result\": \"int\"},\n",
        "        func=add,\n",
        "    )\n",
        ")\n",
        "\n",
        "registry.register(\n",
        "    Tool(\n",
        "        name=\"multiply\",\n",
        "        description=\"Multiply two numbers\",\n",
        "        input_schema=ToolMultiplyArgs,\n",
        "        output_schema={\"result\": \"int\"},\n",
        "        func=multiply,\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "k486HLyDx024"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "registry.list_tools()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jrNs3cNfePD",
        "outputId": "299e4a32-2501-4a4b-d076-352e2e346f4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'add',\n",
              "  'description': 'Add two numbers',\n",
              "  'input_schema': {'properties': {'a': {'title': 'A', 'type': 'integer'},\n",
              "    'b': {'title': 'B', 'type': 'integer'}},\n",
              "   'required': ['a', 'b'],\n",
              "   'title': 'ToolAddArgs',\n",
              "   'type': 'object'}},\n",
              " {'name': 'multiply',\n",
              "  'description': 'Multiply two numbers',\n",
              "  'input_schema': {'properties': {'a': {'title': 'A', 'type': 'integer'},\n",
              "    'b': {'title': 'B', 'type': 'integer'}},\n",
              "   'required': ['a', 'b'],\n",
              "   'title': 'ToolMultiplyArgs',\n",
              "   'type': 'object'}}]"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "registry.get_tool_call_args_type()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8HaVsj_ilZA",
        "outputId": "fad99583-f57f-4cd2-e721-8d3463921c9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "typing.Union[__main__.ToolAddArgs, __main__.ToolMultiplyArgs]"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "registry.get_tool_names()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Llzj29bSmdFc",
        "outputId": "f2dd70a0-ed73-4875-fc7d-ebe74c18b021"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "typing.Literal['add', 'multiply']"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ToolNameLiteral = registry.get_tool_names()\n",
        "ToolArgsUnion = registry.get_tool_call_args_type()\n",
        "\n",
        "class ToolCall(BaseModel):\n",
        "    action: Literal[\"tool\"]\n",
        "    thought: str\n",
        "    tool_name: ToolNameLiteral\n",
        "    args: ToolArgsUnion\n",
        "\n",
        "class FinalAnswer(BaseModel):\n",
        "    action: Literal[\"final\"]\n",
        "    answer: str\n",
        "\n",
        "LLMResponse = Union[ToolCall, FinalAnswer]\n",
        "\n",
        "class GeminiLLM:\n",
        "    def __init__(self, client, tool_registry, model=\"gemini-2.5-flash\"):\n",
        "        self.client = client\n",
        "        self.model = model\n",
        "        self.tool_registry = tool_registry\n",
        "        self.system_instruction = self._create_system_instruction()\n",
        "\n",
        "    def _create_system_instruction(self) -> str:\n",
        "        tools_description = json.dumps(\n",
        "            self.tool_registry.list_tools(),\n",
        "            indent=2\n",
        "        )\n",
        "\n",
        "        system_prompt = \"\"\"\n",
        "You are a conversational AI agent that can interact with external tools.\n",
        "\n",
        "CRITICAL RULES (MUST FOLLOW):\n",
        "- You are NOT allowed to perform operations internally that could be performed by an available tool.\n",
        "- If a tool exists that can perform any part of the task, you MUST use that tool.\n",
        "- You MUST NOT skip tools, even for simple or obvious steps.\n",
        "- You MUST NOT combine multiple operations into a single step unless a tool explicitly supports it.\n",
        "- You may ONLY produce a final answer when no available tool can further advance the task.\n",
        "\n",
        "TOOL USAGE RULES:\n",
        "- Each tool call must perform exactly ONE meaningful operation.\n",
        "- If the task requires multiple operations, you MUST call tools sequentially.\n",
        "- If multiple tools could apply, choose the most specific one.\n",
        "\n",
        "RESPONSE FORMAT (STRICT):\n",
        "- You MUST respond ONLY in valid JSON.\n",
        "- Never include explanations outside JSON.\n",
        "- You must choose exactly one action per response.\n",
        "\n",
        "Tool call format:\n",
        "{\n",
        "  \"action\": \"tool\",\n",
        "  \"thought\": \"...\",\n",
        "  \"tool_name\": \"...\",\n",
        "  \"inputs\": { ... }\n",
        "}\n",
        "\n",
        "Final answer format:\n",
        "{\n",
        "  \"action\": \"final\",\n",
        "  \"answer\": \"...\"\n",
        "}\"\"\" + \"\\n\\nAvailable tools with description:\\n\" + tools_description\n",
        "        return system_prompt\n",
        "\n",
        "    def _format_gemini_chat_history(self, history: list[dict]) -> list:\n",
        "        formatted_history = []\n",
        "        for message in history:\n",
        "            if message[\"role\"] == \"user\":\n",
        "                formatted_history.append(types.Content(\n",
        "                        role=\"user\",\n",
        "                        parts=[\n",
        "                            types.Part.from_text(text=message[\"content\"])\n",
        "                        ]\n",
        "                    )\n",
        "                )\n",
        "            if message[\"role\"] == \"assistant\":\n",
        "                formatted_history.append(types.Content(\n",
        "                        role=\"model\",\n",
        "                        parts=[\n",
        "                            types.Part.from_text(text=message[\"content\"])\n",
        "                        ]\n",
        "                    )\n",
        "                )\n",
        "            if message[\"role\"] == \"tool\":\n",
        "                formatted_history.append(types.Content(\n",
        "                        role=\"tool\",\n",
        "                        parts=[\n",
        "                            types.Part.from_function_response(\n",
        "                                name=message[\"tool_name\"],\n",
        "                                response={'result': message[\"tool_response\"]},\n",
        "                            )\n",
        "                        ]\n",
        "                    )\n",
        "                )\n",
        "        return formatted_history\n",
        "\n",
        "\n",
        "    def generate(self, history: list[dict]) -> str:\n",
        "        gemini_history_format = self._format_gemini_chat_history(history)\n",
        "        response = self.client.models.generate_content(\n",
        "            model=self.model,\n",
        "            contents=gemini_history_format,\n",
        "            config=types.GenerateContentConfig(\n",
        "                temperature=0,\n",
        "                response_mime_type=\"application/json\",\n",
        "                response_schema=LLMResponse,\n",
        "                system_instruction=self.system_instruction,\n",
        "                automatic_function_calling=types.AutomaticFunctionCallingConfig(disable=True)\n",
        "            ),\n",
        "        )\n",
        "        return response.text\n"
      ],
      "metadata": {
        "id": "BW21Wyn9x00M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent:\n",
        "    def __init__(self, llm, tool_registry, max_steps=5):\n",
        "        self.llm = llm\n",
        "        self.tool_registry = tool_registry\n",
        "        self.history = []\n",
        "        self.max_steps = max_steps\n",
        "\n",
        "    def run(self, user_input: str):\n",
        "        self.history.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "        for step in range(self.max_steps):\n",
        "            llm_output = self.llm.generate(self.history)\n",
        "            action = json.loads(llm_output)\n",
        "\n",
        "            if action[\"action\"] == \"tool\":\n",
        "                #print(action[\"thought\"])\n",
        "                self.history.append(\n",
        "                    {\"role\": \"assistant\", \"content\": llm_output}\n",
        "                )\n",
        "                tool = self.tool_registry.get(action[\"tool_name\"])\n",
        "                result = tool(**action[\"args\"])\n",
        "\n",
        "                observation = f\"Tool {tool.name} returned: {result}\"\n",
        "                self.history.append(\n",
        "                    {\"role\": \"tool\", \"tool_name\": tool.name, \"tool_response\": result}\n",
        "                )\n",
        "                continue\n",
        "\n",
        "            if action[\"action\"] == \"final\":\n",
        "                self.history.append(\n",
        "                    {\"role\": \"assistant\", \"content\": llm_output}\n",
        "                )\n",
        "                #print(action[\"answer\"])\n",
        "                return action[\"answer\"]\n",
        "        raise RuntimeError(\"Agent did not terminate within max_steps\")\n"
      ],
      "metadata": {
        "id": "BuyTL5QMx0xQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = GeminiLLM(client, registry)\n",
        "agent = Agent(llm, registry)"
      ],
      "metadata": {
        "id": "wXOzNTGIx0uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm.system_instruction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEk4ckgAoWRI",
        "outputId": "c83664f0-3410-4edd-f476-cbd1d6ebc72c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are a conversational AI agent that can interact with external tools.\n",
            "\n",
            "CRITICAL RULES (MUST FOLLOW):\n",
            "- You are NOT allowed to perform operations internally that could be performed by an available tool.\n",
            "- If a tool exists that can perform any part of the task, you MUST use that tool.\n",
            "- You MUST NOT skip tools, even for simple or obvious steps.\n",
            "- You MUST NOT combine multiple operations into a single step unless a tool explicitly supports it.\n",
            "- You may ONLY produce a final answer when no available tool can further advance the task.\n",
            "\n",
            "TOOL USAGE RULES:\n",
            "- Each tool call must perform exactly ONE meaningful operation.\n",
            "- If the task requires multiple operations, you MUST call tools sequentially.\n",
            "- If multiple tools could apply, choose the most specific one.\n",
            "\n",
            "RESPONSE FORMAT (STRICT):\n",
            "- You MUST respond ONLY in valid JSON.\n",
            "- Never include explanations outside JSON.\n",
            "- You must choose exactly one action per response.\n",
            "\n",
            "Tool call format:\n",
            "{\n",
            "  \"action\": \"tool\",\n",
            "  \"thought\": \"...\",\n",
            "  \"tool_name\": \"...\",\n",
            "  \"inputs\": { ... }\n",
            "}\n",
            "\n",
            "Final answer format:\n",
            "{\n",
            "  \"action\": \"final\",\n",
            "  \"answer\": \"...\"\n",
            "}\n",
            "\n",
            "Available tools with description:\n",
            "[\n",
            "  {\n",
            "    \"name\": \"add\",\n",
            "    \"description\": \"Add two numbers\",\n",
            "    \"input_schema\": {\n",
            "      \"properties\": {\n",
            "        \"a\": {\n",
            "          \"title\": \"A\",\n",
            "          \"type\": \"integer\"\n",
            "        },\n",
            "        \"b\": {\n",
            "          \"title\": \"B\",\n",
            "          \"type\": \"integer\"\n",
            "        }\n",
            "      },\n",
            "      \"required\": [\n",
            "        \"a\",\n",
            "        \"b\"\n",
            "      ],\n",
            "      \"title\": \"ToolAddArgs\",\n",
            "      \"type\": \"object\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"name\": \"multiply\",\n",
            "    \"description\": \"Multiply two numbers\",\n",
            "    \"input_schema\": {\n",
            "      \"properties\": {\n",
            "        \"a\": {\n",
            "          \"title\": \"A\",\n",
            "          \"type\": \"integer\"\n",
            "        },\n",
            "        \"b\": {\n",
            "          \"title\": \"B\",\n",
            "          \"type\": \"integer\"\n",
            "        }\n",
            "      },\n",
            "      \"required\": [\n",
            "        \"a\",\n",
            "        \"b\"\n",
            "      ],\n",
            "      \"title\": \"ToolMultiplyArgs\",\n",
            "      \"type\": \"object\"\n",
            "    }\n",
            "  }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"Hi! Can you add 10 and 32?\")"
      ],
      "metadata": {
        "id": "-0WHKgftx0ro",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ed28bd5-23a1-4d8f-a803-9e441809354d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"Now multiply the result by 2\")"
      ],
      "metadata": {
        "id": "ZMAGlZpjx0o0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_with_agent(agent: Agent):\n",
        "    print(\"Welcome! Type 'exit' to quit.\\n\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() in [\"exit\", \"quit\", \"q\"]:\n",
        "            print(\"Goodbye!\")\n",
        "            break\n",
        "\n",
        "        try:\n",
        "            response = agent.run(user_input)\n",
        "            print(f\"Agent: {response}\")\n",
        "        except RuntimeError as e:\n",
        "            print(f\"Agent error: {e}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Unexpected error: {e}\")"
      ],
      "metadata": {
        "id": "Yakh1MsOx0dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_with_agent(agent)"
      ],
      "metadata": {
        "id": "wSnh14BDx0aw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69810e13-e92f-4a93-e4bc-ed77b01bae6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome! Type 'exit' to quit.\n",
            "\n",
            "You: can you solve this equation step by step: x/3-2=3\n",
            "Agent: x = 15\n",
            "You: q\n",
            "Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.history"
      ],
      "metadata": {
        "id": "_YaQePiKx0WT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc416808-4c78-4e03-c50e-a8f2d5c324eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'user',\n",
              "  'content': 'can you solve this equation step by step: x/3-2=3'},\n",
              " {'role': 'assistant',\n",
              "  'content': '{\\n  \"action\": \"tool\",\\n  \"thought\": \"The first step to solve the equation x/3 - 2 = 3 is to add 2 to both sides. I will use the \\'add\\' tool to calculate 3 + 2.\",\\n  \"tool_name\": \"add\",\\n  \"args\": {\\n    \"a\": 3,\\n    \"b\": 2\\n  }\\n}'},\n",
              " {'role': 'tool', 'tool_name': 'add', 'tool_response': 5},\n",
              " {'role': 'assistant',\n",
              "  'content': '{\\n  \"action\": \"tool\",\\n  \"thought\": \"After adding 2 to both sides, the equation becomes x/3 = 5. The next step is to multiply both sides by 3 to solve for x. I will use the \\'multiply\\' tool to calculate 5 * 3.\",\\n  \"tool_name\": \"multiply\",\\n  \"args\": {\\n    \"a\": 5,\\n    \"b\": 3\\n  }\\n}'},\n",
              " {'role': 'tool', 'tool_name': 'multiply', 'tool_response': 15},\n",
              " {'role': 'assistant',\n",
              "  'content': '{\\n  \"action\": \"final\",\\n  \"answer\": \"x = 15\"\\n}'}]"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = llm.generate([{'role': 'user', 'content': 'hi, Can you add 10 and 32?'},\n",
        " {'role': 'assistant',\n",
        "  'content': '{\\n  \"action\": \"tool\",\\n  \"thought\": \"The user wants to add two numbers, 10 and 32. I should use the \\'add\\' tool for this.\",\\n  \"tool_name\": \"add\",\\n  \"args\": {\\n    \"a\": 10,\\n    \"b\": 32\\n  }\\n}'},\n",
        " {'role': 'tool', 'tool_name': 'add', 'tool_response': 42},\n",
        " {'role': 'assistant',\n",
        "  'content': '{\\n  \"action\": \"final\",\\n  \"answer\": \"42\"\\n}'},\n",
        " {'role': 'user', 'content': 'now multiply that by 2'}])"
      ],
      "metadata": {
        "id": "AACWiqprx0T2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r"
      ],
      "metadata": {
        "id": "Y2z7sIQ5ubxw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}